{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+Z+zF+BPx37PfpRDUk/GU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tada20001/NLP_2023/blob/main/CH19_02_%EC%9E%A0%EC%9E%AC_%EB%94%94%EB%A6%AC%ED%81%B4%EB%A0%88_%ED%95%A0%EB%8B%B9(Latent_Dirichlet_Allocation%2C_LDA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토픽 모델링은 문서의 집합에서 토픽을 찾아내는 프로세스를 말함. LDA는 대표적인 알고리즘임.\n",
        "\n",
        "문서들은 토픽들의 혼합으로 구성되어 있는데, 각 토픽은 확률분포에 기반하여 단어들을 생성한다고 가정함. 데이터가 주어지면 LDA는 문서가 생성되었던 과정을 역추적함.\n",
        "\n",
        "\n",
        "* 참고 링크 : https://lettier.com/projects/lda-topic-modeling/\n",
        "\n",
        "\n",
        "### 1. 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA) 개요\n",
        "----------------\n",
        "우선 LDA에 문서 집합을 입력하면 어떤 결과를 보여주는지 간소화된 예를 살펴보자. 아래와 같이 3개 문서에서 토픽을 찾는다고 하자.\n",
        "\n",
        "* 문서1 : 저는 사과랑 바나나를 먹어요\n",
        "* 문서2 : 우리는 귀여운 강아지가 좋아요\n",
        "* 문서3 : 저의 깜찍하고 귀여운 강아지가 바나나를 먹어요\n",
        "\n",
        "LDA를 수행할 때 문서 집합에서 토픽이 몇개가 존재할지 가정하는 것은 사용자가 직접 해야 함. 여기서는 LDA에 2개의 토픽을 찾는것으로 함. 즉 k=2. \n",
        "\n",
        "LDA가 위의 세문서로부터 2개의 토픽을 찾은 결과는 다음과 같음. 여기서는 LDA 입력 전에 전처리 처리를 했다고 가정함. \n",
        "\n",
        "\n",
        "LDA는 각 문서의 토픽분포와 각 토픽 내의 단어 분포를 추정함\n",
        "\n",
        "<각 문서의 토픽 분포>\n",
        "\n",
        "* 문서1 : 토픽 A 100%\n",
        "* 문서2 : 토픽 B 100%\n",
        "* 문서3 : 토픽 B 60%, 토픽 A 40%\n",
        "\n",
        "\n",
        "<각 토픽의 단어 분포>\n",
        "* 토픽A : 사과 20%, 바나나 40%, 먹어요 40%, 귀여운 0%, 강아지 0%, 깜찍하고 0%, 좋아요 0%\n",
        "* 토픽B : 사과 0%, 바나나 0%, 먹어요 0%, 귀여운 33%, 강아지 33%, 깜찍하고 16%, 좋아요 16%\n",
        "\n",
        "\n",
        "LDA는 토픽의 제목을 정해주지 않지만, 이 시점에서 알고리즘의 사용자는 위 결과로부터 두 토픽이 각각 과일에 대한 토픽과 강아지에 대한 토픽이라고 판단할 수 있음. 이제 LDA에 대해 알아봄.\n",
        "\n",
        "\n",
        "### 2. LDA의 가정\n",
        "----------------\n",
        "LDA는 문서의 집합으로부터 어떤 토픽이 존재하는지 알아내기 위한 알고리즘임. LDA는 빈도수 기반의 표현방법인 BoW 행렬 DTM 또는 TF-IDF 행렬을 입력으로 하는데, 다만 문제는 LDA는 단어의 순서를 고려하지 않는다는 것임.\n",
        "\n",
        "모든 문서 하나 하나가 작성될 때 다음과 같은 과정을 거쳐 작성되었다고 가정함\n",
        "\n",
        "1) 문서에 사용할 단어의 개수 N을 정함 \n",
        "\n",
        "2) 문서에 사용할 토픽의 혼합을 확률분포에 기반하여 결정함\n",
        "\n",
        "3) 문서에 사용할 각 단어를 아래와 같이 정함\n",
        "  * 토픽 분포에서 토픽 T를 확률적으로 고름\n",
        "  * 선택한 토픽 T에서 단어의 출현 확률 분포에 기반해 문서에 사용할 단어를 고름\n",
        "\n",
        "\n",
        "이러한 과정을 통해 문서가 작성되었다는 가정 하에 LDA는 토픽을 뽑아내기 위해 위 과정을 역으로 추적하는 역공학(reverse engineering)을 수행함\n",
        "\n",
        "### 3. LDA 수행하기\n",
        "-----------------\n",
        "LDA 프로세스 정리.\n",
        "\n",
        "1) 사용자는 알고리즘에게 토픽의 개수 k를 알려줌 : 토픽의 개수가 정해지면, k개의 토픽이 M개의 전체 문서에 걸쳐 분포되어 있다고 가정함\n",
        "\n",
        "2) 모든 단어를 k개 토픽 중 하나에 각각 할당함 : 랜덤으로 할당하기 때문에 한단어가 한문서에 2회 이상 등장하면 각 단어는 서로 다른 토픽에 할당될 수 있음\n",
        "\n",
        "3) 모든 문서의 모든 단어에 아래의 사항을 반복함\n",
        "\n",
        "* 임의의 문서의 각 단어 w는 자신은 잘못된 토픽에 할당되어 있지만, 다른 단어들은 올바른 토픽에 할당되어져 있다고 가정함. 이에, 단어 w는 아래의 두가지 기준에 따라 토픽이 재할당됨\n",
        "  * p(topic t | document d) : 문서 d의 단어들 중 토픽 t에 해당하는 단어들의 비\n",
        "  * p(word w | topic t) : 각 토픽들 t에서 해당 단어 w의 분포\n"
      ],
      "metadata": {
        "id": "TmiGdUkBxd1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 잠재 디리클레 할당(LDA)과 잠재의미 분석(LSA)의 차이\n",
        "--------------------------------------\n",
        "* LSA : DTM을 차원 축소하여 축소차원에서 근접 단어들을 토픽으로 묶음\n",
        "* LDA : 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 토픽을 추출함\n",
        "\n",
        "\n",
        "### 5. 실습을 통한 이해\n",
        "---------------\n",
        "LDA는 gensim을 사용함\n",
        "\n",
        "\n",
        "#### 1) 정수 인코딩과 단어 집합 만들기\n"
      ],
      "metadata": {
        "id": "J9vtBoBdiHUo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ulw5GJj-xNxe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = datasets.data\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy6bxuv_UGI_",
        "outputId": "88ebc721-6121-4078-fc27-29d7443227d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리\n",
        "news_df = pd.DataFrame({'document': documents})\n",
        "news_df['clean_doc'] = news_df['document'].str.replace('[^a-zA-Z]', ' ')\n",
        "\n",
        "# 길이가 3이하 제거\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
        "\n",
        "# 전체 단어에 소문자 변환\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcengbDOU5E-",
        "outputId": "a032e855-7a18-4e7f-ed1e-e5a286a5ca2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b496bddd358c>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  news_df['clean_doc'] = news_df['document'].str.replace('[^a-zA-Z]', ' ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인\n",
        "news_df['clean_doc'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "3Xi35FHnV1EQ",
        "outputId": "26ce222b-b893-4a0a-8921-d6675949d378"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())  # 토큰화"
      ],
      "metadata": {
        "id": "vbXCMSmfYnd9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 제거\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMhHg54Af2L-",
        "outputId": "a7608b8a-1a27-42bd-a54b-32cbd4b33bf2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 불용어 제거\n",
        "\n",
        "tokenized_doc[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qokrS3JUWuQb",
        "outputId": "5a391072-2905-43b8-a992-88c2d433282c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [well, sure, story, seem, biased, disagree, st...\n",
              "1    [yeah, expect, people, read, actually, accept,...\n",
              "2    [although, realize, principle, strongest, poin...\n",
              "3    [notwithstanding, legitimate, fuss, proposal, ...\n",
              "4    [well, change, scoring, playoff, pool, unfortu...\n",
              "Name: clean_doc, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수인코딩과 각 뉴스의 단어 빈도수 도출(word_id, word_frequency)\n",
        "from gensim import corpora"
      ],
      "metadata": {
        "id": "qHvvqrP2W_lu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(tokenized_doc)\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_doc]\n",
        "print(corpus[1])  #(정수인코딩, 빈도수) 튜플로 도출"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyjF31VValyx",
        "outputId": "f106939d-b492-4a34-e555-38cbc8b050b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(52, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 2), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어별 정수값 확인 방법\n",
        "print(dictionary[60])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVNORlSYa5Cw",
        "outputId": "061b9bbd-cf8e-4897-a47b-6c6a16da11b5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_doc[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGpwgRh5cRvn",
        "outputId": "6621a7a9-027d-4098-98d3-4b92dce8aedc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) LDA 모델 훈련\n",
        "\n",
        "기존의 뉴스 데이터가 총 20개의 카테고리를 가지고 있었으므로 토픽의 개수를 20으로 하여 LDA 모델을 학습함"
      ],
      "metadata": {
        "id": "vi0eg-Stddce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "NUM_TOPICS = 20\n",
        "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=NUM_TOPICS, id2word=dictionary, passes=15)\n",
        "topics = ldamodel.print_topics(num_words=4)\n",
        "for topic in topics:\n",
        "  print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2qhAinsctd_",
        "outputId": "879ee29d-9578-4d45-e988-4b0b71042c53"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.023*\"please\" + 0.023*\"mail\" + 0.018*\"send\" + 0.017*\"email\"')\n",
            "(1, '0.022*\"game\" + 0.022*\"team\" + 0.016*\"games\" + 0.014*\"play\"')\n",
            "(2, '0.009*\"bike\" + 0.007*\"cars\" + 0.007*\"engine\" + 0.005*\"road\"')\n",
            "(3, '0.020*\"encryption\" + 0.017*\"chip\" + 0.016*\"keys\" + 0.015*\"clipper\"')\n",
            "(4, '0.013*\"drive\" + 0.011*\"system\" + 0.009*\"card\" + 0.008*\"disk\"')\n",
            "(5, '0.013*\"nist\" + 0.012*\"crypt\" + 0.010*\"ncsl\" + 0.010*\"colorado\"')\n",
            "(6, '0.011*\"sabbath\" + 0.011*\"rockefeller\" + 0.009*\"allocation\" + 0.009*\"mask\"')\n",
            "(7, '0.041*\"space\" + 0.016*\"nasa\" + 0.009*\"data\" + 0.009*\"launch\"')\n",
            "(8, '0.023*\"ground\" + 0.013*\"wiring\" + 0.013*\"neutral\" + 0.012*\"circuit\"')\n",
            "(9, '0.006*\"pain\" + 0.006*\"water\" + 0.006*\"food\" + 0.006*\"years\"')\n",
            "(10, '0.011*\"people\" + 0.010*\"would\" + 0.005*\"government\" + 0.005*\"many\"')\n",
            "(11, '0.012*\"people\" + 0.010*\"would\" + 0.009*\"jesus\" + 0.008*\"believe\"')\n",
            "(12, '0.013*\"president\" + 0.011*\"university\" + 0.009*\"national\" + 0.008*\"april\"')\n",
            "(13, '0.015*\"armenian\" + 0.013*\"israel\" + 0.013*\"jews\" + 0.010*\"turkish\"')\n",
            "(14, '0.022*\"said\" + 0.014*\"went\" + 0.010*\"people\" + 0.009*\"told\"')\n",
            "(15, '0.012*\"vram\" + 0.008*\"simm\" + 0.006*\"nick\" + 0.006*\"canon\"')\n",
            "(16, '0.018*\"gordon\" + 0.017*\"pitt\" + 0.016*\"banks\" + 0.015*\"surrender\"')\n",
            "(17, '0.020*\"file\" + 0.013*\"program\" + 0.009*\"windows\" + 0.009*\"available\"')\n",
            "(18, '0.020*\"would\" + 0.017*\"like\" + 0.014*\"think\" + 0.012*\"good\"')\n",
            "(19, '0.029*\"scsi\" + 0.009*\"nubus\" + 0.009*\"easter\" + 0.009*\"feds\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 단어 앞에 붙은 수치는 단어의 해당 토픽에 대한 기여도를 보여줌. 또한, 맨 앞에 있는 토픽번호는 0부터 시작하므로 총 20개의 토픽은 0부터 19까지 번호가 할당되어져 있음. \n",
        "\n",
        "\n",
        "passes는 알고리즘의 동작횟수를 말하는데, 알고리즘이 결정하는 토픽의 값이 적절히 수렴할 수 있도록 충분히 적당한 횟수를 정해주면 됨.\n",
        "\n",
        "여기에서는 총 15회를 수행하였음. 그리고 num_words=4로 4개의 단어만 출력하도록 함.\n",
        "\n",
        "만약 10개 단어를 출력하고 싶으면 아래의 토드를 수행하면 됨"
      ],
      "metadata": {
        "id": "Bp2Szf9Ffn6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = ldamodel.print_topics(num_words=10)\n",
        "for topic in topics:\n",
        "  print(topic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUsnfeadd-1X",
        "outputId": "05162b96-6907-40e9-d897-e07d0a670dcb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, '0.023*\"please\" + 0.023*\"mail\" + 0.018*\"send\" + 0.017*\"email\" + 0.015*\"thanks\" + 0.014*\"list\" + 0.014*\"information\" + 0.011*\"address\" + 0.011*\"info\" + 0.008*\"anyone\"')\n",
            "(1, '0.022*\"game\" + 0.022*\"team\" + 0.016*\"games\" + 0.014*\"play\" + 0.013*\"season\" + 0.011*\"league\" + 0.011*\"hockey\" + 0.011*\"players\" + 0.009*\"period\" + 0.008*\"teams\"')\n",
            "(2, '0.009*\"bike\" + 0.007*\"cars\" + 0.007*\"engine\" + 0.005*\"road\" + 0.005*\"cover\" + 0.005*\"miles\" + 0.005*\"front\" + 0.005*\"wire\" + 0.005*\"insurance\" + 0.004*\"right\"')\n",
            "(3, '0.020*\"encryption\" + 0.017*\"chip\" + 0.016*\"keys\" + 0.015*\"clipper\" + 0.013*\"security\" + 0.012*\"privacy\" + 0.011*\"government\" + 0.010*\"public\" + 0.009*\"system\" + 0.009*\"technology\"')\n",
            "(4, '0.013*\"drive\" + 0.011*\"system\" + 0.009*\"card\" + 0.008*\"disk\" + 0.007*\"problem\" + 0.007*\"used\" + 0.006*\"know\" + 0.006*\"like\" + 0.006*\"need\" + 0.006*\"also\"')\n",
            "(5, '0.013*\"nist\" + 0.012*\"crypt\" + 0.010*\"ncsl\" + 0.010*\"colorado\" + 0.009*\"plaintext\" + 0.007*\"zone\" + 0.007*\"marc\" + 0.007*\"patent\" + 0.006*\"john\" + 0.006*\"blocks\"')\n",
            "(6, '0.011*\"sabbath\" + 0.011*\"rockefeller\" + 0.009*\"allocation\" + 0.009*\"mask\" + 0.009*\"cross\" + 0.009*\"paul\" + 0.008*\"planes\" + 0.007*\"plane\" + 0.007*\"kidney\" + 0.007*\"rows\"')\n",
            "(7, '0.041*\"space\" + 0.016*\"nasa\" + 0.009*\"data\" + 0.009*\"launch\" + 0.008*\"earth\" + 0.008*\"satellite\" + 0.007*\"shuttle\" + 0.006*\"orbit\" + 0.006*\"lunar\" + 0.006*\"moon\"')\n",
            "(8, '0.023*\"ground\" + 0.013*\"wiring\" + 0.013*\"neutral\" + 0.012*\"circuit\" + 0.010*\"panel\" + 0.009*\"current\" + 0.008*\"voltage\" + 0.008*\"judges\" + 0.008*\"circuits\" + 0.008*\"connected\"')\n",
            "(9, '0.006*\"pain\" + 0.006*\"water\" + 0.006*\"food\" + 0.006*\"years\" + 0.005*\"cause\" + 0.005*\"disease\" + 0.004*\"medical\" + 0.004*\"high\" + 0.004*\"body\" + 0.004*\"patients\"')\n",
            "(10, '0.011*\"people\" + 0.010*\"would\" + 0.005*\"government\" + 0.005*\"many\" + 0.004*\"right\" + 0.004*\"make\" + 0.004*\"case\" + 0.004*\"even\" + 0.004*\"well\" + 0.004*\"state\"')\n",
            "(11, '0.012*\"people\" + 0.010*\"would\" + 0.009*\"jesus\" + 0.008*\"believe\" + 0.007*\"know\" + 0.007*\"think\" + 0.005*\"christian\" + 0.005*\"many\" + 0.005*\"bible\" + 0.005*\"life\"')\n",
            "(12, '0.013*\"president\" + 0.011*\"university\" + 0.009*\"national\" + 0.008*\"april\" + 0.008*\"research\" + 0.007*\"health\" + 0.007*\"washington\" + 0.006*\"program\" + 0.006*\"information\" + 0.006*\"american\"')\n",
            "(13, '0.015*\"armenian\" + 0.013*\"israel\" + 0.013*\"jews\" + 0.010*\"turkish\" + 0.010*\"armenians\" + 0.008*\"israeli\" + 0.008*\"jewish\" + 0.007*\"greek\" + 0.007*\"turkey\" + 0.006*\"people\"')\n",
            "(14, '0.022*\"said\" + 0.014*\"went\" + 0.010*\"people\" + 0.009*\"told\" + 0.009*\"came\" + 0.008*\"home\" + 0.008*\"took\" + 0.008*\"started\" + 0.007*\"know\" + 0.007*\"says\"')\n",
            "(15, '0.012*\"vram\" + 0.008*\"simm\" + 0.006*\"nick\" + 0.006*\"canon\" + 0.006*\"clip\" + 0.006*\"math\" + 0.006*\"coprocessor\" + 0.005*\"invalid\" + 0.005*\"cooling\" + 0.005*\"wanna\"')\n",
            "(16, '0.018*\"gordon\" + 0.017*\"pitt\" + 0.016*\"banks\" + 0.015*\"surrender\" + 0.015*\"soon\" + 0.014*\"quebec\" + 0.013*\"skepticism\" + 0.012*\"intellect\" + 0.011*\"shameful\" + 0.011*\"cadre\"')\n",
            "(17, '0.020*\"file\" + 0.013*\"program\" + 0.009*\"windows\" + 0.009*\"available\" + 0.009*\"files\" + 0.009*\"window\" + 0.008*\"output\" + 0.008*\"version\" + 0.007*\"using\" + 0.007*\"entry\"')\n",
            "(18, '0.020*\"would\" + 0.017*\"like\" + 0.014*\"think\" + 0.012*\"good\" + 0.012*\"know\" + 0.010*\"time\" + 0.009*\"well\" + 0.009*\"much\" + 0.008*\"could\" + 0.008*\"really\"')\n",
            "(19, '0.029*\"scsi\" + 0.009*\"nubus\" + 0.009*\"easter\" + 0.009*\"feds\" + 0.008*\"cellular\" + 0.006*\"obfuscate\" + 0.006*\"cluster\" + 0.006*\"alomar\" + 0.006*\"burst\" + 0.005*\"brad\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) LDA 시각화하기\n",
        "시각화를 위해 pyLDAvis 설치가 필요함. "
      ],
      "metadata": {
        "id": "TyULhdBIhq6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXEskfFUhnoP",
        "outputId": "92598505-ecdb-458b-ce44-487258d1d943"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (0.40.0)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.24.3)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.10.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (7.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (0.18.3)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.7.2->pyLDAvis) (2.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.17.0->pyLDAvis) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.17.0->pyLDAvis) (2023.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pyLDAvis) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pyLDAvis) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->pyLDAvis) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pyLDAvis) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.17.0->pyLDAvis) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models"
      ],
      "metadata": {
        "id": "6pOPobCCh0L3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
        "\n",
        "#pyLDAvis.display(vis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqY5bN-qh9C5",
        "outputId": "4163ce24-9c75-4906-fc1b-b93a88910802"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:concurrent.futures:exception calling callback for <Future at 0x7fd0cf2cf040 state=finished raised BrokenProcessPool>\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n",
            "    call_item = call_queue.get(block=True, timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "ModuleNotFoundError: No module named 'pandas.core.indexes.numeric'\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/_base.py\", line 26, in _invoke_callbacks\n",
            "    callback(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 385, in __call__\n",
            "    self.parallel.dispatch_next()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 834, in dispatch_next\n",
            "    if not self.dispatch_one_batch(self._original_iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 556, in apply_async\n",
            "    future = self._workers.submit(SafeFunction(func))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/reusable_executor.py\", line 176, in submit\n",
            "    return super().submit(fn, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 1129, in submit\n",
            "    raise self._flags.broken\n",
            "joblib.externals.loky.process_executor.BrokenProcessPool: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BrokenProcessPool",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 391, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\nModuleNotFoundError: No module named 'pandas.core.indexes.numeric'\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-de32c7097ccc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#pyLDAvis.display(vis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyLDAvis/gensim_models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_topic_info\u001b[0;34m(topic_term_dists, topic_proportion, term_frequency, term_topic_freq, vocab, lambda_step, R, n_jobs, start_index)\u001b[0m\n\u001b[1;32m    271\u001b[0m    \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm_topic_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m    \u001b[0mtop_topic_terms_freq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m    \u001b[0mtop_topic_terms_freq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Topic'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m    \u001b[0;31m# we filter to Freq >= 0.5 to avoid sending too much data to the browser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/_base.py\u001b[0m in \u001b[0;36m_invoke_callbacks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_done_callbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'exception calling callback for {self!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, out)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \"\"\"\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSafeFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_future_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/reusable_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 raise ShutdownExecutorError(\n",
            "\u001b[0;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) 문서별 토픽 분포 보기\n",
        "\n",
        "각 문서의 토픽 분포는 이미 훈련된 LDA 모델인 ldamodel[]에 전체 데이터가 정수 인코딩된 결과를 넣은 후에 확인이 가능함. 여기에서는 상위 5개 문서만 확인함."
      ],
      "metadata": {
        "id": "ikEXHz_slWIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "  if i == 5:\n",
        "    break\n",
        "  print(i, '번째 문서의 topic 비율은', topic_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wro2w7JUiKMK",
        "outputId": "dc9834a5-c439-4659-f2d0-4bfbc0a2ad08"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 문서의 topic 비율은 [(4, 0.023191622), (5, 0.049878158), (10, 0.14050865), (11, 0.33026433), (13, 0.41948438), (18, 0.025173567)]\n",
            "1 번째 문서의 topic 비율은 [(9, 0.05978697), (11, 0.49811935), (14, 0.030098785), (15, 0.02761466), (18, 0.36461803)]\n",
            "2 번째 문서의 topic 비율은 [(1, 0.046760786), (5, 0.017713374), (10, 0.16278163), (13, 0.29913965), (18, 0.46087527)]\n",
            "3 번째 문서의 topic 비율은 [(2, 0.05596703), (3, 0.32127374), (4, 0.063700855), (10, 0.1889689), (18, 0.27894858), (19, 0.0800175)]\n",
            "4 번째 문서의 topic 비율은 [(0, 0.111899436), (1, 0.34376517), (11, 0.36742392), (18, 0.1472693)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gOkv3utLl9z6",
        "outputId": "7fefa1b8-9d3c-46f2-dcea-08eada4489b9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'biased'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 출력 결과에서 (숫자, 확률)은 각각 토픽번호와 해당 토픽이 해당 문서에서 차지하는 분포도를 의미함. 예를 들어, 0번째 문서의 토픽 비율에서 (4, 0.023191622)는 4번 토픽이 23% 분포를 가지는 것을 의미함. 이를 데이터 프레임형식으로 출력함."
      ],
      "metadata": {
        "id": "xX5yKLPHmKov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_topictable_per_doc(ldamodel, corpus):\n",
        "  topic_list_new = []\n",
        "\n",
        "  for i, topic_list in enumerate(ldamodel[corpus]):\n",
        "    doc = topic_list[0] if ldamodel.per_word_topics else topic_list\n",
        "    doc = sorted(doc, key=lambda x: (x[1]), reverse=True)  # 비중 내림차순\n",
        "    \n",
        "    for j, (topic_num, prop_topic) in enumerate(doc):\n",
        "      if j == 0:\n",
        "        topic_list_new.append([int(topic_num), dictionary[int(topic_num)], round(prop_topic, 4), topic_list])\n",
        "      else:\n",
        "        break\n",
        "  return pd.DataFrame(topic_list_new)"
      ],
      "metadata": {
        "id": "Hh08OsHamD0J"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topictable = make_topictable_per_doc(ldamodel, corpus)\n",
        "topictable = topictable.reset_index()\n",
        "topictable.columns = ['문서번호', '가장 비중이 높은 토픽번호', '가장 비중이 높은 토픽', '가장 높은 토픽의 비중', '각 토픽의 비중']\n",
        "topictable[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ZbjDOiXdnQpB",
        "outputId": "c6af26a6-cc4c-4d4c-dbeb-2cd8b874031b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   문서번호  가장 비중이 높은 토픽번호 가장 비중이 높은 토픽  가장 높은 토픽의 비중  \\\n",
              "0     0              13    europeans        0.4197   \n",
              "1     1              11     disagree        0.4980   \n",
              "2     2              18       ignore        0.4609   \n",
              "3     3               3         away        0.3213   \n",
              "4     4              11     disagree        0.3674   \n",
              "5     5              11     disagree        0.7139   \n",
              "6     6               4       biased        0.3470   \n",
              "7     7              18       ignore        0.3098   \n",
              "8     8              11     disagree        0.2458   \n",
              "9     9              18       ignore        0.4131   \n",
              "\n",
              "                                            각 토픽의 비중  \n",
              "0  [(4, 0.023135796), (5, 0.04987826), (10, 0.139...  \n",
              "1  [(9, 0.059786715), (11, 0.49801734), (14, 0.03...  \n",
              "2  [(1, 0.046760384), (5, 0.017713375), (10, 0.16...  \n",
              "3  [(2, 0.05599415), (3, 0.32127926), (4, 0.06369...  \n",
              "4  [(0, 0.11190306), (1, 0.34376398), (11, 0.3673...  \n",
              "5               [(11, 0.71386826), (19, 0.24520636)]  \n",
              "6  [(4, 0.34704548), (8, 0.11050618), (10, 0.1016...  \n",
              "7  [(2, 0.18673246), (5, 0.0473757), (9, 0.021589...  \n",
              "8  [(4, 0.21488655), (7, 0.03319339), (9, 0.13529...  \n",
              "9  [(2, 0.2805147), (3, 0.09458226), (4, 0.157151...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41db1363-bc22-4bf2-9820-97d5039524ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>문서번호</th>\n",
              "      <th>가장 비중이 높은 토픽번호</th>\n",
              "      <th>가장 비중이 높은 토픽</th>\n",
              "      <th>가장 높은 토픽의 비중</th>\n",
              "      <th>각 토픽의 비중</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>europeans</td>\n",
              "      <td>0.4197</td>\n",
              "      <td>[(4, 0.023135796), (5, 0.04987826), (10, 0.139...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>disagree</td>\n",
              "      <td>0.4980</td>\n",
              "      <td>[(9, 0.059786715), (11, 0.49801734), (14, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>ignore</td>\n",
              "      <td>0.4609</td>\n",
              "      <td>[(1, 0.046760384), (5, 0.017713375), (10, 0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>away</td>\n",
              "      <td>0.3213</td>\n",
              "      <td>[(2, 0.05599415), (3, 0.32127926), (4, 0.06369...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>disagree</td>\n",
              "      <td>0.3674</td>\n",
              "      <td>[(0, 0.11190306), (1, 0.34376398), (11, 0.3673...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>disagree</td>\n",
              "      <td>0.7139</td>\n",
              "      <td>[(11, 0.71386826), (19, 0.24520636)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>biased</td>\n",
              "      <td>0.3470</td>\n",
              "      <td>[(4, 0.34704548), (8, 0.11050618), (10, 0.1016...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>ignore</td>\n",
              "      <td>0.3098</td>\n",
              "      <td>[(2, 0.18673246), (5, 0.0473757), (9, 0.021589...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>disagree</td>\n",
              "      <td>0.2458</td>\n",
              "      <td>[(4, 0.21488655), (7, 0.03319339), (9, 0.13529...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>ignore</td>\n",
              "      <td>0.4131</td>\n",
              "      <td>[(2, 0.2805147), (3, 0.09458226), (4, 0.157151...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41db1363-bc22-4bf2-9820-97d5039524ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41db1363-bc22-4bf2-9820-97d5039524ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41db1363-bc22-4bf2-9820-97d5039524ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vZl91KBWvoEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}