{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775d6742",
   "metadata": {},
   "source": [
    "단방향 LSTM으로 텍스트 분류를 수행할 수도 있으나, 양방향 LSTM을 사용하는 것이 더 강력함. 여기에 추가적으로 어텐션 메커니즘을 사용할 수도 있음\n",
    "\n",
    "### 1. IMDB 리뷰 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b9fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e629f2",
   "metadata": {},
   "source": [
    "IMDB 리뷰 데이터는 최대 단어 개수를 10,000으로 제한하고 훈련데이터와 테스트 데이터를 받아옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f929b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fcf1d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8eb26fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d1a05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이:  2494\n",
      "리뷰의 평균 길이:  238.71364\n"
     ]
    }
   ],
   "source": [
    "# 데이터가 이미 정수 인코딩된 상태이므로, 남은 전처리는 패딩 뿐임. 리뷰의 최대 길이와 평균길이 확인\n",
    "\n",
    "print('리뷰의 최대 길이: ', max(len(x) for x in X_train))\n",
    "print('리뷰의 평균 길이: ', sum(len(x) for x in X_train) / len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3d796",
   "metadata": {},
   "source": [
    "리뷰의 최대길이는 2,494이며, 리뷰의 평균길이는 약 238임. 여기에서는 평균 길이보다 좀더 크게 데이터를 패딩함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "849b2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e74fee",
   "metadata": {},
   "source": [
    "훈련용 리뷰와 테스트용 리뷰의 길이 모두 500이 됨\n",
    "\n",
    "### 2. 바다나우 어텐션(Bahdanau Attention)\n",
    "------\n",
    "여기서 사용할 어텐션은 바다나우 어텐션임\n",
    "\n",
    "어텐션 스코어 함수란, 주어진 query와 모든 key에 대해 유사도를 측정하는 함수를 말함. 그리고 닷 프로덕트 어텐션에서는 query와 key의 유사도를 구하는 방법이 내적(dot product)이었음. 다음은 닷 프로덕트 어텐션의 스코어 함수를 보여줌\n",
    "\n",
    "$$score(query,\\ key) = query^Tkey$$\n",
    "\n",
    "바다나우 어텐션은 아래와 같이 어텐션 스코어 함수를 사용함\n",
    "\n",
    "$$score(query,\\ key) = V^Ttanh(W_{1}key + W_{2}query)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad2ed3",
   "metadata": {},
   "source": [
    "이 어텐션 스코어 함수를 사용하여 어텐션 메커니즘을 구현하면 됨. 그런데 텍스트 분류에서 어텐션 메커니즘을 사용하는 이유는 무엇을까? RNN의 마지막 은닉상태는 예측을 위해 사용됨. 그런데 이 RNN의 마지막 은닉상태는 몇가지 유용한 정보들을 손실한 상태임. 그래서 RNN이 time step을 지나며 손실했던 정보를 다시 참고하고자 하는 것임\n",
    "\n",
    "이는 다시 말해 RNN의 모든 은닉상태들을 다시 한번 참고하겠다는 것이며, 이를 위해 어텐션 메커니즘을 사용하는 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872409c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d9c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)  # value\n",
    "        \n",
    "    def call(self, values, query): # 단, key와 value는 같음\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # score 계산을 위해 뒤에서 할 덧셈을 위해 차원을 변경해 줌\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d4b69",
   "metadata": {},
   "source": [
    "### 3. 양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b276d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03151718",
   "metadata": {},
   "source": [
    "##### 1) 입력층과 임베딩층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "305a7d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f10cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequece_input = Input(shape=(max_length,), dtype='int32')\n",
    "embedded_sequences = Embedding(vocab_size, 128, input_length=max_length, \\\n",
    "                               mask_zero=True)(sequece_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da9cd0",
   "metadata": {},
   "source": [
    "10000개 단어들을 128차원의 벡터로 임베딩하도록 설계함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e9e08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 500, 128])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba8c7c1",
   "metadata": {},
   "source": [
    "##### 2) 양방향 LSTM 설계  \n",
    "* 두층을 설계하기 때문에, 첫번째 층에 두번째 층을 쌓을 예정이므로 return_sequences=True로 설정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07e3acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 층\n",
    "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True))(embedded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda2afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째 층 설계\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional\\\n",
    "(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dcffb0",
   "metadata": {},
   "source": [
    "각 상태의 크기를 출력해 봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d337dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
     ]
    }
   ],
   "source": [
    "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423ae75",
   "metadata": {},
   "source": [
    "순방향 LSTM의 은닉상태와 셀상태를 forward_h, forward_c에 저장하고, 역방향 LSTM의 은닉상태와 셀상태를 backward_h, backward_c에 저장함\n",
    "\n",
    "각 은닉상태나 셀상태의 경우, 128차원을 가지고, lstm은 (500 x 128)의 크기를 가짐. forward 방향과 backward 방향이 연결된 hidden state 벡터가 모든 시점에 대해 존재함을 의미함\n",
    "\n",
    "양방향 LSTM을 사용할 경우에는 순방향 LSTM과 역방향 LSTM 각각 은닉상태와 셀상태를 가지므로, 양방향 LSTM의 은닉상태와 셀상태를 사용하려면 두방향의 LSTM의 상태들을 연결해주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeae1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h])  # 은닉상태\n",
    "state_c = Concatenate()([forward_c, backward_c])  # 셀 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3937251a",
   "metadata": {},
   "source": [
    "어텐션 메커니즘에서는 은닉상태를 사용함. 이를 입력으로 컨텍스트 벡터를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce468a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = BahdanauAttention(64) #  가중치 크기 정의\n",
    "context_vector, attention_weights = attention(lstm, state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a07f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([None, 128]), TensorShape([None, 500, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dbfd7f",
   "metadata": {},
   "source": [
    "컨텍스트 벡터를 밀집층(dense layer)에 통과시키고, 이진분류이므로 최종 출력층에 1개의 뉴런을 배치하고, 활성화 함수로 시그모이드 함수를 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ace04fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(20, activation='relu')(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation='sigmoid')(dropout)\n",
    "model = Model(inputs=sequece_input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ab6d5",
   "metadata": {},
   "source": [
    "옵티마이저로 아담 옵티마이저를 사용하고 모델을 컴파일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5873b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1ab34",
   "metadata": {},
   "source": [
    "시그모이드 함수를 사용하므로 손실함수로 binary_crossentropy를 사용함. 다음으로 모델 훈련함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb3db091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 2890s 29s/step - loss: 0.4727 - accuracy: 0.7652 - val_loss: 0.2941 - val_accuracy: 0.8791\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 2833s 29s/step - loss: 0.2439 - accuracy: 0.9131 - val_loss: 0.2887 - val_accuracy: 0.8830\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 2855s 29s/step - loss: 0.1874 - accuracy: 0.9350 - val_loss: 0.3326 - val_accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=3, batch_size=256, \n",
    "                    validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a19811",
   "metadata": {},
   "source": [
    "검증 데이터로 테스트 데이터를 사용하여 에포크가 끌날때마다 테스트 데이터에 대한 정확도를 출력하도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43564119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 137s 175ms/step - loss: 0.3326 - accuracy: 0.8772\n",
      "\n",
      " 테스트 정확도: 0.8772\n"
     ]
    }
   ],
   "source": [
    "print('\\n 테스트 정확도: %.4f' % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee6d42e",
   "metadata": {},
   "source": [
    "87.72% 정확도를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b5d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
